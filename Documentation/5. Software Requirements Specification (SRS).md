# Software Requirements Specification

|   |   |
| ----------- | ----------- |
| Version | 1.0 |
| Prepared By | Nikki Wood |
| Document Status | COMPLETE |
| Date Updated | 04/12/2021 | 

---

## Table of Contents
| **1.** | [**Introduction**](#1-introduction) |
| ------ | ---------------- |
| 1.1 | Purpose |
| 1.2 | Document Conventions |
| 1.3 | Intended Audience and Reading Suggestions |
| 1.4 | Product Scope | 
| 1.5 | References |
---
| **2.** | [**Overall Description**](#2-overall-description) |
| ------ | ---------------- |
| 2.1 | Product Perspective |
| 2.2 | Product Functions |
| 2.3 | User Classes and Characteristics |
| 2.4 | Operating Environment | 
| 2.5 | Design and Implementation Constraints |
| 2.6 | User Documentation |
| 2.7 | Assumptions and Dependencies |
---
| **3.** | **External Interface Requirements** |
| ------ | ---------------- |
| 3.1 | User Interfaces |
| 3.2 | Software Interfaces |
| 3.3 | Communications Interfaces |
---
| **4.** | **System Features** |
| ------ | ---------------- |
| 4.1 | System Feature 1 |
| 4.2 | System Feature 2 |
---
| **5.** | **Other Nonfunctional Requirements** |
| ------ | ---------------- |
| 5.1 | Performance Requirements |
| 5.2 | Security Requirements |
| 5.3 | Software Quality Attributes |
| 5.4 | Business Rules | 
---
| **6.** | **Other Requirements** |
| ------ | ---------------- |
### Appendix A: Glossary
### Appendix B: Analysis Models
### C: To Be Determined List

---
## Revision History
| Name | Date | Reason For Changes | Version |
| ---- | ---- | ------------------ | ------- |
| Initial Version (Draft) | 01/11/2021 | - | 0.1 |
| Mid-term Revision | 03/20/2021 | Adding Requirements | 0.2 |
| End of term Revision | 04/12/2021 | Adding more now that all other documentation is done | 0.3 |

## 1. Introduction

### 1.1  Purpose
This document is a representation of the Chromesthesia Response Replicator AI application. It describes how the user and software communicate to allow the user to view the sound-to-color synesthetic response of one individual. 

### 1.2  Document Conventions
Within this document:
- "Sample" or "song sample" will refer to an inputted song.
- "Category" (relating to "response") will refer to one of the three categories our subject is using to describe her synesthetic response. Categories include: Luminosity, Color, and Texture.
- "response" will refer to the combination of 'correct answers' for each category. For example, a response to a song might be "smoky black", "light soft purple", etc.
- "the AI" will refer to the part of this project that will identify patterns and assign a response to an inputted song sample. 
- "the Application" will refer to the part of this project that will take an inputted song, compile a response (from the AI), and output that response to the user.
- "Software" will refer to the project itself, including both the AI and the application.
- "synesthete" will refer to any individual with synesthesia
- "synesthetic response" will refer to the visuals seen by any synesthete with sound-to-color synesthesia (chromesthesia).
- "Subject", "Client", and "our synesthete" will refer to Meredith Turner, the synesthete that will be providing our training set. She will also be assisting with this project.

### 1.3  Intended Audience and Reading Suggestions.
This document is intended to be read by the Client, Nikki Wood, and Dr. Gary Cantrell. The Client should look for how this documentation represents how she intends the Software to function. Nikki Wood will use this document as she plans, builds, and tests the Software in order to fulfill the requirements and functions specified. Dr. Gary Cantrell will read and critique this document for errors and to give feedback.

### 1.4  Product Scope
This Software will give those who do not have chromesthesia a taste of what it might be like to have these sound-to-color conversions. It will also amplify our Subject's understanding of the correlation between her visual responses and the different genres, tempos, or timbre (sound/tone quality) in music.

---
## 2. Overall Description
### 2.1  Product Perspective
The Software will allow users to input a song into the Application. This Sample will be sent to the AI to create a response prediction. The Application will then deliver the response back to the user, so that they might see the visual interpretation of their song through the eyes of a synesthete. See Figure 2.1
<br/>
![picture 1](../images/6da32d20f6a561597d4c7ffaed7321fba0a2f2e8a034f70b3a4cb805a3df79e1.png)  

### 2.2  Product Functions
The Software will function as shown in Figure 2.2

![picture 2](../images/4f257313b3a98110a584188f7b409656c45a38a76aee960429825e8594bb7a83.png)  


### 2.3  User Classes and Characteristics
There exists only one class of User for this Software. This user class will be able to access all functions of the Software. 

### 2.4  Operating Environment

The operating environment of this software is through Windows Explorer (moving test sample into the test folder) and through the command line (running script and generating prediction).

### 2.5  Design and Implementation Constraints
The Software must be able to access the three model files, but should be able to be ran on any computer with Python installed. 

### 2.6  User Documentation 
To test a sample:
- Be sure that the sample is 30 seconds in length
- Move the sample into the \src\test_samples\TESTING folder. 
- Note: If there is more than one sample in this folder, only the first (alphabetical order) will be analyzed. 
- Run the main.py file by using the following command:
  ```
    python -m src
  ```
- If you would like to use a different location, you can specify the path of the testing folder using -p or --path
- Again, make sure there is only one sample in the folder
  ```
    python -m src -p C:\Users\user\Downloads\mytest
  ```
- To view other commands, use --help.
  ```
  python -m src --help
  ```

### 2.7  Assumptions and Dependencies
|   |   |
| - | - |
| AS1 | User will only test one song sample at a time. | 
| AS2 | User will either use the provided TESTING folder, or will provide their own folder with one sample contained in it. |
| DE1 | User will already have Python installed and added to path on the host machine. |
| DE2 | User will have access to 30 second samples | 

---
## 3. External Interface Requirements
### 3.1  User Interfaces
The User will interface with Window Explorer (or other folder navigation system) to move their sample into the correct folder. They will then use the command line to run the script and receive a prediction.

### 3.2  Software Interfaces
This Software will use pre-saved models, included in the src\models folder. 

### 3.3  Communications Interfaces
This Software will output the prediction via command line.

---

## 4. System Features

### 4.1 Data Extraction for Training
#### 4.1.1 Description/Priority
    Extract MFCCs and labels for all testing/training data.
    High Priority. Application will not be able to classify song labels without the MFCC and correct label.

#### 4.1.2 Stimulus/Response Sequence
    Stimulus: User provides a path to all song samples, sorted into folders named with the correct category.
    Response: System extracts MFCCs and labels for each song and saves them in a .json file. Status is outputted to user.

#### 4.1.3 Functional Requirements
    |   |   |
    | - | - |
    | FR 4.1.3.1 | Software must be able to extract a dynamic (changing) number of categories. | 
    | FR 4.1.3.2 | Software must be able to extract a dynamic (changing) number of samples from each category. | 
    | FR 4.1.3.3 | Software must output a .json file that can be parsed into the mapping (category), mfcc (input), and label (output)

### 4.2  Training AI Model
#### 4.2.1  Description/Priority
    Classify Color/Texture/Luminosity for all testing/training data.
    High Priority. Application will not be able to predict a synesthetic response without this component.

#### 4.2.2 Stimulus/Response Sequence
    Stimulus: User provides a path to training data.
    Response: System trains and saves the model, outputting the accuracy.

#### 4.2.3 Functional Requirements
    |   |   |
    | - | - |
    | FR 4.2.3.1 | Software must output an accuracy percentage for each epoch. | 
    | FR 4.2.3.2 | Software must output an Accuracy Evaluation (graphical representation of accuracy over numer of epochs)| 
    | FR 4.2.3.3 | Software must output a correctly labeled confusion matrix |

### 4.3 Data Extraction for Single Sample Prediction
#### 4.3.1  Description/Priority
    Extract MFCC for single sample of 30 second length.
    High Priority. Application will need to extract the MFCC in order to get a prediction from the saved models.

#### 4.3.2 Stimulus/Response Sequence
    Stimulus: User provides a 30 second sample in the TESTING folder
    Response: System extracts MFCC and stores it to be classified. 

#### 4.2.3 Functional Requirements
    |   |   |
    | - | - |
    | FR 4.3.3.1 | Software must save mfcc for all three model inputs. | 

### 4.4 Generate Prediction for Single Sample
#### 4.4.1 Description/Priority
    Send sample MFCC to all 3 models, convert the returned integer into a classification string. 
    High Priority. This is the final output and overall goal of the program.
    
#### 4.4.2 Stimulus/Response Sequence
    Stimulus: MFCC has been extracted from the user's provided sample.
    Response: System collects and compiles the models' predictions into a user-friendly description which is outputted to the command line.

#### 4.2.3 Functional Requirements
    |   |   |
    | - | - |
    | FR 4.4.3.1 | Software must save each model's output. | 
    | FR 4.2.3.2 | Software must convert each model's output into a string representation of the corresponding category classification. | 
    | FR 4.2.3.3 | Software must output all three predictions (as strings) to the command line in a way that is readable to the user. |

---
## Main Requirements
| # | Requirement Description | Success Metric | Notes |
| --- | --- | --- | --- |
| 1 | Reflect on the goal of finding the expected outcome for each category with 50% accuracy | 1 - 2 paragraph reflection: Was the AI's prediction correct at least 50% of the time? What parameters seemed to affect the success rate? | - |
| 2 | Application compiles each expected outcome and returns the 'correct answer' as one response (command line) | Given a song, does the program output a written description of the AI's prediction (e.g. "light, sparkly blue") | - |
| 3 | Minimum of 12 hours of research (Neural nets, similar AI projects, python application with AI, etc.) | On the project's Time Report, was there a minimum of 12 hours in the **Research** section? | - |
| 4 | Find at least 1 sample recorded for each combination | On the Training Samples excel sheet, was there at least 1 recorded sample for every combination? (154 possible) If not, was there an explanation from the subject as to why? | - |
| 5 | Reflect on the expansion of my knowledge and comprehension of Python | Minimum of 3 paragraphs: How did your understanding of Python expand through the course of this project? What did you learn about using Python with AI? | - |
| 6 | Keep detailed documentation throughout the process | Is there a Documentation folder easily found from GitHub? Does it include *at least* the following: Timeline, Contract, Process Model Justification, SRS, PRD,  | - | 
## User interaction and design
> After the team fleshes out the solution for each user story, link design explorations and wireframes to the page. 

|   |   |
| ----------- | ----------- |
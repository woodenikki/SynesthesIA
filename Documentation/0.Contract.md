# Capstone Student Project Contract

> **Submitted on:** 01/29/2021
> 
> **Updated on:** 04/08/2021
> 
> **Submitted by:** Nikki Wood

## Background
Chromesthesia, also known as sound-to-color synesthesia, is a rare phenomenon in which an individual perceives non-visual stimulus visually. For example, they  may hear a song and see a specific color; they may observe someone's personality as specific scenery in their head; or they may recount their emotions visually, such as excitement being described as an electric blue.

## Project Description

Because synesthesia is not identical for every person, the goal of this project is to create an AI to see if it can learn and replicate the synesthetic responses of one young adult woman. 

The test subject will listen to 300 30-second intervals of songs from different genres and then record her synesthetic responses as they relate to three categories: luminosity, color, and texture. 

> **Luminosity** refers to the brightness of the color and quantity of light. Some colors may appear muted, while others are bright and vibrant. This value will simply be recorded as either *Yes* or *No*.

> **Color** will be broken into 11 options: *Red*, *Orange*, *Yellow*, *Green*, *Blue*, *Purple*, *Pink*, *Black*, *White*, *Gray*, and *Brown*. 

> **Texture** also supports the overall impression of a color. Texture categories will be *Sparkly*, *Spiky*, *Woody*, *Smoky*, *Smooth*, *Soft*, and *None*.

These responses will act as the training set for the AI. Since each combination will mean something entirely different to our subject, we will end up with 154 (2 * 11 * 7) possible responses. The AI will be trained on one category at a time, starting with Color, Texture, then Luminosity. Each category should have a minimum of 15 songs in each category. If not, the subject will need to search out songs to meet this requirement.

After the AI has been trained, we should be able to give it a song sample and expect an accurate prediction for what our test subject's response would be for each category when listening to the same sample.

The AI will output the overall accuracy of the model, as well as a confusion matrix to show correct and incorrect category guesses.

## Project Concentration
This project will show competencies in the **Artificial Intelligence** and **Software Engineering**. 

### Artificial Intelligence
This project will be using deep learning and other intelligent technologies in order to find the trends and correlations between music and our test subject's synesthetic responses. 

### Software Engineering
Detailed documentation on how the model was made, how it works, and what the results mean will be an integral part of this project. Applying a process model and requirement model will give me more exposure and familiarity to the Software Engineering Process and will prepare me for the field after graduation. 

## Objectives

### Main
  - Reflect on the goal of finding the expected outcome for each category with 50% accuracy
  - Application compiles each expected outcome and returns the 'correct answer' as one response (command line)
  - Minimum of 12 hours of research (Neural nets, similar AI projects, python application with AI, etc.)  
  - Find at least 15 samples for each category
  - Reflect on the expansion of my knowledge and comprehension of AI, Deep Learning, and Neural Nets
  - Keep detailed documentation throughout the process

### Secondary
  - Reflect on the goal of finding the expected outcome for each category with 70% accuracy
  - GUI to choose a song & get display result (color)
  - Synesthesia literary review

### Tertiary
  - Reflect on the goal of finding the expected outcome for each category with 90% accuracy
  - Analysis of results and how they can relate to Synesthesia.
  - GUI displays resulting color with luminosity and texture
  - Publication of results

### Deliverable Items
  - [x] Code Generated: [main.py](../src/__main__.py), [live_classifier.py](../src/live_classifier.py), [build_model.py](../src/build_model.py), [extract_data](../src/extract_data.py)
  - [x] Accuracy [Report](https://drive.google.com/file/d/1zSFwNzc7aQ2I8wNxLzGFGn--V7_go92y/view?usp=sharing) and [Reflection](6.%20Accuracy%20Reflection.md)
  - [x] Neural Net and Deep Learning [practice in Python](https://github.com/woodenikki/SynesthesIA/tree/main/practice)
  - [x] Data and Responses [Excel sheet](https://docs.google.com/spreadsheets/d/1HJfHXcbVR-pNbT7ZG6pJSjnzLiJLgVJDMIFB4BtXrLc/edit?usp=sharing)
  - [x] Reflection(s) of [knowledge expansion](8.%20Project%20Evaluation.md#reflect-on-the-expansion-of-my-knowledge-and-comprehension-of-ai-deep-learning-and-neural-nets) and [ojbectives](8.%20Project%20Evaluation.md#objective-reflections)
  - [x] [Doucmentation](https://github.com/woodenikki/SynesthesIA/tree/main/Documentation) kept through process
  - [x] [Time report](8.%20Time%20Report.md)
  - [x] [Final Presentation](https://docs.google.com/presentation/d/1K_DkJ5v7R2aWCPY0kKZC4Zgahlbz9XpY1vBRZODq0hk/edit?usp=sharing)
  - [x] [Literary review](https://docs.google.com/document/d/1UWc7Ig1uaU3RLGmGximw67Pj6JJ1DHLD26NWGjQ-WpA/edit?usp=sharing) (Secondary)
  - [ ] Report for Publication (Tertiary, INCOMPLETE)

## References
- [Meredith Turner: Guide and Explanation to the Inside of My Head](https://docs.google.com/document/d/1L-aEVjcOL6bL0Th3yhh1tt27FycrrxFBiCsxGzAi7W4/edit?usp=sharing)
- [Capstone Project Expectations](https://docs.google.com/document/d/13Mp3DABw9eqoL4gIi42bVtJYqQPWsr1azxqJp43JgAM/edit)

## Signatures

Competency: ____________________________________

Specialty Professor: _____________________________ Date: ____________


Competency: ____________________________________

Specialty Professor: _____________________________ Date: ____________


Capstone Professor: _____________________________ Date: ____________


I understand that the final assessment of my project will be based on the information contained in this report.

Student: _____________________________ Date: ____________
